{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#CatBoost-с-GridSearchCV\" data-toc-modified-id=\"CatBoost-с-GridSearchCV-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>CatBoost с GridSearchCV</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>CatBoost</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки и данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функции для очистки и лемматизации текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "def lemmatize(text):\n",
    "    l = WordNetLemmatizer()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemm_list = []\n",
    "    for word in word_list:\n",
    "        lemm_list.append(l.lemmatize(word))\n",
    "    lemm_text = \" \".join(lemm_list)\n",
    "    return lemm_text\n",
    "\n",
    "def clear_text(text):\n",
    "    re_text = re.sub(r\"[^a-zA-Z ]\", \" \", text)\n",
    "    re_text = re.sub(r\"[UTC]\", \"\", re_text)\n",
    "    re_text = re_text.lower()\n",
    "    return \" \".join(re_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he love apple'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(clear_text(\"He loves apples\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем функцию на 2 строке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Очищенный и лемматизированный текст: d aww he match this background colour i m seemingly stuck with hank talk january\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст:\", data['text'][1])\n",
    "print(\"Очищенный и лемматизированный текст:\", lemmatize(clear_text(data['text'][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i m se...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clear_text'] = data['text'].apply(clear_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем очищенный текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  d aww he matches this background colour i m se...   \n",
       "2  hey man i m really not trying to edit war it s...   \n",
       "3  more i can t make any real suggestions on impr...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                               lemms  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemms'] = data['clear_text'].apply(lemmatize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы будем использовать кросс-валидацию, то разделим данные на выборки и составим pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['text', 'toxic', 'clear_text'], axis=1)\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119678, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(119678,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(39893, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(39893,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=27)\n",
    "\n",
    "display(features_train.shape)\n",
    "display(target_train.shape)\n",
    "\n",
    "display(features_test.shape)\n",
    "display(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим данные на баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы сильно несбалансированые, это нужно будет учитывать при моделировании:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя f1_valid: 0.7428364187411\n",
      "CPU times: user 2min 14s, sys: 1min 47s, total: 4min 1s\n",
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_lg = Pipeline([('count_tf_idf', TfidfVectorizer(stop_words=stop_words)), \n",
    "                ('logistic_regression', LogisticRegression(random_state=27, class_weight='balanced'))])\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lg, X=features_train['lemms'].values, y=target_train, cv=5, scoring=f1_scorer) \n",
    "final_score = pd.Series(scores).mean()\n",
    "print('Средняя f1_valid:', final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Decision_Tree</th>\n",
       "      <th>Random_Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.742836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic Decision_Tree Random_Forest\n",
       "F1  0.742836           NaN           NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Logistic', 'Decision_Tree', 'Random_Forest']\n",
    "indexes = ['F1']\n",
    "table_f1 = pd.DataFrame(columns=columns, index=indexes)\n",
    "table_f1['Logistic']['F1'] = final_score\n",
    "table_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 339 ms, total: 2min 41s\n",
      "Wall time: 2min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('count_tf_idf',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('dtc', DecisionTreeClassifier())]),\n",
       "             param_grid={'dtc__max_depth': [1, 2, 4]},\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe_dtc = Pipeline([('count_tf_idf', TfidfVectorizer(stop_words=stop_words)), \n",
    "                ('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "parameters = {'dtc__max_depth' : [1, 2, 4]}\n",
    "\n",
    "grid = GridSearchCV(pipe_dtc, parameters, scoring = f1_scorer)\n",
    "grid.fit(features_train['lemms'].values, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc__max_depth': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Decision_Tree</th>\n",
       "      <th>Random_Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.449989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic Decision_Tree Random_Forest\n",
       "F1  0.742836      0.449989           NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_f1['Decision_Tree']['F1'] = final_score\n",
    "table_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 32s, sys: 880 ms, total: 4min 32s\n",
      "Wall time: 4min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('count_tf_idf',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('rfc', RandomForestClassifier())]),\n",
       "             param_grid={'rfc__max_depth': [1, 2, 4],\n",
       "                         'rfc__n_estimators': [5, 10]},\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe_dtc = Pipeline([('count_tf_idf', TfidfVectorizer(stop_words=stop_words)), \n",
    "                ('rfc', RandomForestClassifier())])\n",
    "\n",
    "parameters = {'rfc__n_estimators' : [5, 10],\n",
    "              'rfc__max_depth' : [1, 2, 4]\n",
    "             }\n",
    "\n",
    "grid = GridSearchCV(pipe_dtc, parameters, scoring = f1_scorer)\n",
    "grid.fit(features_train['lemms'].values, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__max_depth': 1, 'rfc__n_estimators': 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>Decision_Tree</th>\n",
       "      <th>Random_Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.449989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic Decision_Tree Random_Forest\n",
       "F1  0.742836      0.449989           0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_f1['Random_Forest']['F1'] = final_score\n",
    "table_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost с GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим GridSearchCV для поиска наилучших параметров CatBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  d aww he matches this background colour i m se...   \n",
       "2  hey man i m really not trying to edit war it s...   \n",
       "3  more i can t make any real suggestions on impr...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                               lemms  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he match this background colour i m seem...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestion on impro...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 1)\n",
      "(159571,)\n"
     ]
    }
   ],
   "source": [
    "features_cat = data.drop(['text', 'toxic', 'lemms'], axis=1)\n",
    "target_cat = data['toxic']\n",
    "print(features_cat.shape)\n",
    "print(target_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_cat, features_test_cat, target_train_cat, target_test_cat = train_test_split(features_cat, target_cat, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 1)\n",
      "(119678,)\n",
      "(39893, 1)\n",
      "(39893,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_cat.shape)\n",
    "print(target_train_cat.shape)\n",
    "print(features_test_cat.shape)\n",
    "print(target_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5684689\ttotal: 343ms\tremaining: 2m 51s\n",
      "100:\tlearn: 0.1438126\ttotal: 28.5s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.1355708\ttotal: 55.3s\tremaining: 1m 22s\n",
      "300:\tlearn: 0.1311425\ttotal: 1m 22s\tremaining: 54.3s\n",
      "400:\tlearn: 0.1281760\ttotal: 1m 49s\tremaining: 27s\n",
      "499:\tlearn: 0.1256052\ttotal: 2m 16s\tremaining: 0us\n",
      "0:\tlearn: 0.5697721\ttotal: 285ms\tremaining: 2m 22s\n",
      "100:\tlearn: 0.1448949\ttotal: 28.2s\tremaining: 1m 51s\n",
      "200:\tlearn: 0.1361330\ttotal: 55.3s\tremaining: 1m 22s\n",
      "300:\tlearn: 0.1312323\ttotal: 1m 22s\tremaining: 54.5s\n",
      "400:\tlearn: 0.1281980\ttotal: 1m 49s\tremaining: 27s\n",
      "499:\tlearn: 0.1254306\ttotal: 2m 16s\tremaining: 0us\n",
      "0:\tlearn: 0.5695689\ttotal: 284ms\tremaining: 2m 21s\n",
      "100:\tlearn: 0.1452058\ttotal: 28.9s\tremaining: 1m 54s\n",
      "200:\tlearn: 0.1368699\ttotal: 56.1s\tremaining: 1m 23s\n",
      "300:\tlearn: 0.1323878\ttotal: 1m 23s\tremaining: 55s\n",
      "400:\tlearn: 0.1294065\ttotal: 1m 50s\tremaining: 27.2s\n",
      "499:\tlearn: 0.1269069\ttotal: 2m 16s\tremaining: 0us\n",
      "0:\tlearn: 0.5700132\ttotal: 294ms\tremaining: 2m 26s\n",
      "100:\tlearn: 0.1461556\ttotal: 28.5s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.1373438\ttotal: 56s\tremaining: 1m 23s\n",
      "300:\tlearn: 0.1327408\ttotal: 1m 22s\tremaining: 54.8s\n",
      "400:\tlearn: 0.1298181\ttotal: 1m 49s\tremaining: 27.1s\n",
      "499:\tlearn: 0.1272663\ttotal: 2m 16s\tremaining: 0us\n",
      "0:\tlearn: 0.5690541\ttotal: 286ms\tremaining: 2m 22s\n",
      "100:\tlearn: 0.1450826\ttotal: 28.6s\tremaining: 1m 52s\n",
      "200:\tlearn: 0.1364135\ttotal: 56.4s\tremaining: 1m 23s\n",
      "300:\tlearn: 0.1318965\ttotal: 1m 23s\tremaining: 55.2s\n",
      "400:\tlearn: 0.1286485\ttotal: 1m 50s\tremaining: 27.4s\n",
      "499:\tlearn: 0.1259596\ttotal: 2m 17s\tremaining: 0us\n",
      "0:\tlearn: 0.5684689\ttotal: 290ms\tremaining: 4m 49s\n",
      "100:\tlearn: 0.1438126\ttotal: 28.8s\tremaining: 4m 16s\n",
      "200:\tlearn: 0.1355708\ttotal: 55.9s\tremaining: 3m 42s\n",
      "300:\tlearn: 0.1311425\ttotal: 1m 22s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.1281760\ttotal: 1m 49s\tremaining: 2m 43s\n",
      "500:\tlearn: 0.1255956\ttotal: 2m 16s\tremaining: 2m 16s\n",
      "600:\tlearn: 0.1234594\ttotal: 2m 44s\tremaining: 1m 48s\n",
      "700:\tlearn: 0.1215513\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "800:\tlearn: 0.1200062\ttotal: 3m 38s\tremaining: 54.4s\n",
      "900:\tlearn: 0.1185534\ttotal: 4m 6s\tremaining: 27.1s\n",
      "999:\tlearn: 0.1171763\ttotal: 4m 33s\tremaining: 0us\n",
      "0:\tlearn: 0.5697721\ttotal: 280ms\tremaining: 4m 39s\n",
      "100:\tlearn: 0.1448949\ttotal: 28.5s\tremaining: 4m 13s\n",
      "200:\tlearn: 0.1361330\ttotal: 55.8s\tremaining: 3m 41s\n",
      "300:\tlearn: 0.1312323\ttotal: 1m 22s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.1281980\ttotal: 1m 49s\tremaining: 2m 43s\n",
      "500:\tlearn: 0.1254138\ttotal: 2m 16s\tremaining: 2m 16s\n",
      "600:\tlearn: 0.1230694\ttotal: 2m 44s\tremaining: 1m 48s\n",
      "700:\tlearn: 0.1211309\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "800:\tlearn: 0.1193433\ttotal: 3m 38s\tremaining: 54.3s\n",
      "900:\tlearn: 0.1178047\ttotal: 4m 5s\tremaining: 27s\n",
      "999:\tlearn: 0.1161901\ttotal: 4m 33s\tremaining: 0us\n",
      "0:\tlearn: 0.5695689\ttotal: 287ms\tremaining: 4m 47s\n",
      "100:\tlearn: 0.1452058\ttotal: 28.8s\tremaining: 4m 16s\n",
      "200:\tlearn: 0.1368699\ttotal: 55.9s\tremaining: 3m 42s\n",
      "300:\tlearn: 0.1323878\ttotal: 1m 23s\tremaining: 3m 13s\n",
      "400:\tlearn: 0.1294065\ttotal: 1m 50s\tremaining: 2m 45s\n",
      "500:\tlearn: 0.1268772\ttotal: 2m 18s\tremaining: 2m 17s\n",
      "600:\tlearn: 0.1245155\ttotal: 2m 45s\tremaining: 1m 50s\n",
      "700:\tlearn: 0.1225916\ttotal: 3m 13s\tremaining: 1m 22s\n",
      "800:\tlearn: 0.1209958\ttotal: 3m 40s\tremaining: 54.8s\n",
      "900:\tlearn: 0.1195778\ttotal: 4m 7s\tremaining: 27.2s\n",
      "999:\tlearn: 0.1182244\ttotal: 4m 35s\tremaining: 0us\n",
      "0:\tlearn: 0.5700132\ttotal: 286ms\tremaining: 4m 46s\n",
      "100:\tlearn: 0.1461556\ttotal: 28.3s\tremaining: 4m 11s\n",
      "200:\tlearn: 0.1373438\ttotal: 55.6s\tremaining: 3m 41s\n",
      "300:\tlearn: 0.1327408\ttotal: 1m 22s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.1298181\ttotal: 1m 49s\tremaining: 2m 43s\n",
      "500:\tlearn: 0.1272500\ttotal: 2m 16s\tremaining: 2m 16s\n",
      "600:\tlearn: 0.1250984\ttotal: 2m 44s\tremaining: 1m 48s\n",
      "700:\tlearn: 0.1231165\ttotal: 3m 11s\tremaining: 1m 21s\n",
      "800:\tlearn: 0.1213961\ttotal: 3m 38s\tremaining: 54.3s\n",
      "900:\tlearn: 0.1198640\ttotal: 4m 5s\tremaining: 27s\n",
      "999:\tlearn: 0.1185439\ttotal: 4m 32s\tremaining: 0us\n",
      "0:\tlearn: 0.5690541\ttotal: 281ms\tremaining: 4m 40s\n",
      "100:\tlearn: 0.1450826\ttotal: 28.4s\tremaining: 4m 13s\n",
      "200:\tlearn: 0.1364135\ttotal: 55.7s\tremaining: 3m 41s\n",
      "300:\tlearn: 0.1318965\ttotal: 1m 22s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.1286485\ttotal: 1m 49s\tremaining: 2m 43s\n",
      "500:\tlearn: 0.1259421\ttotal: 2m 17s\tremaining: 2m 16s\n",
      "600:\tlearn: 0.1236662\ttotal: 2m 44s\tremaining: 1m 49s\n",
      "700:\tlearn: 0.1217756\ttotal: 3m 12s\tremaining: 1m 22s\n",
      "800:\tlearn: 0.1201664\ttotal: 3m 39s\tremaining: 54.5s\n",
      "900:\tlearn: 0.1187302\ttotal: 4m 7s\tremaining: 27.1s\n",
      "999:\tlearn: 0.1174729\ttotal: 4m 33s\tremaining: 0us\n",
      "0:\tlearn: 0.5683473\ttotal: 373ms\tremaining: 3m 5s\n",
      "100:\tlearn: 0.1335100\ttotal: 39.6s\tremaining: 2m 36s\n",
      "200:\tlearn: 0.1242246\ttotal: 1m 18s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.1189635\ttotal: 1m 57s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.1148153\ttotal: 2m 35s\tremaining: 38.3s\n",
      "499:\tlearn: 0.1114156\ttotal: 3m 12s\tremaining: 0us\n",
      "0:\tlearn: 0.5695350\ttotal: 370ms\tremaining: 3m 4s\n",
      "100:\tlearn: 0.1336573\ttotal: 39.4s\tremaining: 2m 35s\n",
      "200:\tlearn: 0.1237088\ttotal: 1m 18s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.1182937\ttotal: 1m 56s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.1142380\ttotal: 2m 34s\tremaining: 38.1s\n",
      "499:\tlearn: 0.1109056\ttotal: 3m 11s\tremaining: 0us\n",
      "0:\tlearn: 0.5695861\ttotal: 371ms\tremaining: 3m 4s\n",
      "100:\tlearn: 0.1351978\ttotal: 39.6s\tremaining: 2m 36s\n",
      "200:\tlearn: 0.1254222\ttotal: 1m 19s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.1201112\ttotal: 1m 57s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.1160378\ttotal: 2m 34s\tremaining: 38.2s\n",
      "499:\tlearn: 0.1127866\ttotal: 3m 11s\tremaining: 0us\n",
      "0:\tlearn: 0.5699542\ttotal: 370ms\tremaining: 3m 4s\n",
      "100:\tlearn: 0.1356013\ttotal: 39.1s\tremaining: 2m 34s\n",
      "200:\tlearn: 0.1253177\ttotal: 1m 18s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.1199384\ttotal: 1m 56s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.1158303\ttotal: 2m 35s\tremaining: 38.4s\n",
      "499:\tlearn: 0.1123847\ttotal: 3m 13s\tremaining: 0us\n",
      "0:\tlearn: 0.5690816\ttotal: 359ms\tremaining: 2m 59s\n",
      "100:\tlearn: 0.1348379\ttotal: 39.1s\tremaining: 2m 34s\n",
      "200:\tlearn: 0.1246258\ttotal: 1m 18s\tremaining: 1m 56s\n",
      "300:\tlearn: 0.1191585\ttotal: 1m 57s\tremaining: 1m 17s\n",
      "400:\tlearn: 0.1151815\ttotal: 2m 35s\tremaining: 38.3s\n",
      "499:\tlearn: 0.1119235\ttotal: 3m 12s\tremaining: 0us\n",
      "0:\tlearn: 0.5683473\ttotal: 371ms\tremaining: 6m 10s\n",
      "100:\tlearn: 0.1335100\ttotal: 39.7s\tremaining: 5m 53s\n",
      "200:\tlearn: 0.1242246\ttotal: 1m 19s\tremaining: 5m 14s\n",
      "300:\tlearn: 0.1189635\ttotal: 1m 57s\tremaining: 4m 32s\n",
      "400:\tlearn: 0.1148153\ttotal: 2m 35s\tremaining: 3m 51s\n",
      "500:\tlearn: 0.1113791\ttotal: 3m 12s\tremaining: 3m 12s\n",
      "600:\tlearn: 0.1087722\ttotal: 3m 49s\tremaining: 2m 32s\n",
      "700:\tlearn: 0.1063109\ttotal: 4m 26s\tremaining: 1m 53s\n",
      "800:\tlearn: 0.1041163\ttotal: 5m 4s\tremaining: 1m 15s\n",
      "900:\tlearn: 0.1019731\ttotal: 5m 41s\tremaining: 37.5s\n",
      "999:\tlearn: 0.1002269\ttotal: 6m 17s\tremaining: 0us\n",
      "0:\tlearn: 0.5695350\ttotal: 377ms\tremaining: 6m 16s\n",
      "100:\tlearn: 0.1336573\ttotal: 39.7s\tremaining: 5m 53s\n",
      "200:\tlearn: 0.1237088\ttotal: 1m 19s\tremaining: 5m 14s\n",
      "300:\tlearn: 0.1182937\ttotal: 1m 57s\tremaining: 4m 32s\n",
      "400:\tlearn: 0.1142380\ttotal: 2m 34s\tremaining: 3m 51s\n",
      "500:\tlearn: 0.1108846\ttotal: 3m 12s\tremaining: 3m 11s\n",
      "600:\tlearn: 0.1080221\ttotal: 3m 49s\tremaining: 2m 32s\n",
      "700:\tlearn: 0.1054659\ttotal: 4m 26s\tremaining: 1m 53s\n",
      "800:\tlearn: 0.1033075\ttotal: 5m 3s\tremaining: 1m 15s\n",
      "900:\tlearn: 0.1012943\ttotal: 5m 40s\tremaining: 37.5s\n",
      "999:\tlearn: 0.0993207\ttotal: 6m 17s\tremaining: 0us\n",
      "0:\tlearn: 0.5695861\ttotal: 381ms\tremaining: 6m 20s\n",
      "100:\tlearn: 0.1351978\ttotal: 39.6s\tremaining: 5m 52s\n",
      "200:\tlearn: 0.1254222\ttotal: 1m 18s\tremaining: 5m 13s\n",
      "300:\tlearn: 0.1201112\ttotal: 1m 57s\tremaining: 4m 33s\n",
      "400:\tlearn: 0.1160378\ttotal: 2m 36s\tremaining: 3m 53s\n",
      "500:\tlearn: 0.1127712\ttotal: 3m 13s\tremaining: 3m 12s\n",
      "600:\tlearn: 0.1100153\ttotal: 3m 51s\tremaining: 2m 33s\n",
      "700:\tlearn: 0.1074409\ttotal: 4m 29s\tremaining: 1m 54s\n",
      "800:\tlearn: 0.1051124\ttotal: 5m 8s\tremaining: 1m 16s\n",
      "900:\tlearn: 0.1030453\ttotal: 5m 45s\tremaining: 38s\n",
      "999:\tlearn: 0.1012291\ttotal: 6m 23s\tremaining: 0us\n",
      "0:\tlearn: 0.5699542\ttotal: 372ms\tremaining: 6m 11s\n",
      "100:\tlearn: 0.1356013\ttotal: 39.4s\tremaining: 5m 50s\n",
      "200:\tlearn: 0.1253177\ttotal: 1m 19s\tremaining: 5m 14s\n",
      "300:\tlearn: 0.1199384\ttotal: 1m 57s\tremaining: 4m 33s\n",
      "400:\tlearn: 0.1158303\ttotal: 2m 37s\tremaining: 3m 54s\n",
      "500:\tlearn: 0.1123471\ttotal: 3m 15s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.1095913\ttotal: 3m 55s\tremaining: 2m 36s\n",
      "700:\tlearn: 0.1070455\ttotal: 4m 32s\tremaining: 1m 56s\n",
      "800:\tlearn: 0.1049891\ttotal: 5m 11s\tremaining: 1m 17s\n",
      "900:\tlearn: 0.1028895\ttotal: 5m 49s\tremaining: 38.4s\n",
      "999:\tlearn: 0.1010253\ttotal: 6m 28s\tremaining: 0us\n",
      "0:\tlearn: 0.5690816\ttotal: 385ms\tremaining: 6m 24s\n",
      "100:\tlearn: 0.1348379\ttotal: 43.1s\tremaining: 6m 23s\n",
      "200:\tlearn: 0.1246258\ttotal: 1m 25s\tremaining: 5m 37s\n",
      "300:\tlearn: 0.1191585\ttotal: 2m 7s\tremaining: 4m 56s\n",
      "400:\tlearn: 0.1151815\ttotal: 2m 51s\tremaining: 4m 15s\n",
      "500:\tlearn: 0.1119035\ttotal: 3m 32s\tremaining: 3m 31s\n",
      "600:\tlearn: 0.1091385\ttotal: 4m 11s\tremaining: 2m 46s\n",
      "700:\tlearn: 0.1066530\ttotal: 4m 48s\tremaining: 2m 3s\n",
      "800:\tlearn: 0.1043759\ttotal: 5m 26s\tremaining: 1m 21s\n",
      "900:\tlearn: 0.1022771\ttotal: 6m 5s\tremaining: 40.1s\n",
      "999:\tlearn: 0.1003782\ttotal: 6m 44s\tremaining: 0us\n",
      "0:\tlearn: 0.5639373\ttotal: 461ms\tremaining: 7m 40s\n",
      "100:\tlearn: 0.1330236\ttotal: 51.2s\tremaining: 7m 36s\n",
      "200:\tlearn: 0.1235394\ttotal: 1m 43s\tremaining: 6m 49s\n",
      "300:\tlearn: 0.1185577\ttotal: 2m 33s\tremaining: 5m 55s\n",
      "400:\tlearn: 0.1147555\ttotal: 3m 19s\tremaining: 4m 57s\n",
      "500:\tlearn: 0.1117046\ttotal: 4m 5s\tremaining: 4m 4s\n",
      "600:\tlearn: 0.1090644\ttotal: 4m 50s\tremaining: 3m 13s\n",
      "700:\tlearn: 0.1067710\ttotal: 5m 38s\tremaining: 2m 24s\n",
      "800:\tlearn: 0.1047556\ttotal: 6m 23s\tremaining: 1m 35s\n",
      "900:\tlearn: 0.1028750\ttotal: 7m 8s\tremaining: 47.1s\n",
      "999:\tlearn: 0.1010929\ttotal: 7m 52s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=<catboost.core.CatBoostClassifier object at 0x7fc54385b310>,\n",
       "             param_grid={'depth': [2, 4], 'iterations': [500, 1000],\n",
       "                         'learning_rate': [0.1]},\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(text_features=['clear_text'])\n",
    "\n",
    "parameters = {'learning_rate' : [0.1],\n",
    "              'iterations'    : [500, 1000],\n",
    "              'depth' : [2, 4] }\n",
    "\n",
    "grid = GridSearchCV(model, parameters, scoring = f1_scorer)\n",
    "grid.fit(features_train_cat, target_train_cat,  verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 4, 'iterations': 1000, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7692505121773023"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "По итогу получили следующие значения F1 на кросс-валидации:\n",
    "\n",
    "- Logistic 0.742836\n",
    "- Decision_Tree 0.449989\n",
    "- Random_Forest\t0.0\n",
    "- CatBoost 0.769250\t\t\n",
    "\t\t\n",
    "Лучше всех справляется градиентный бустинг от Яндекса при 'depth': 4, 'iterations': 1000, 'learning_rate': 0.1. Есть вероятность что он переобучился, поэтому попробуем теперь настроить его по-другому."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим выборки для обучения CatBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 1)\n",
      "(119678,)\n",
      "(39893, 1)\n",
      "(39893,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_cat.shape)\n",
    "print(target_train_cat.shape)\n",
    "print(features_test_cat.shape)\n",
    "print(target_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку классы сильно несбалансированны, то необходимо выставить атрибут stratified = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку в данном проекте нам необходимо достичь максимального значения F1, то будем следить за ней и AUC во время обучения по графику. \n",
    "\n",
    "F1 будет максимальной там, где будет наибольшее значение AUC, поэтому для валидации будем использовать AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение будем останавливать если в течении 30 итераций метрика не меняется или начала ухудшаться. Сделать это позволяет параметр early_stopping_rounds = 30."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим кросс-валидацию для обучения CatBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aacc97372fd0455c91429d61a71fa1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "\n",
      "bestTest = 0.9704724636\n",
      "bestIteration = 793\n",
      "\n",
      "Training on fold [1/5]\n",
      "\n",
      "bestTest = 0.9701205034\n",
      "bestIteration = 446\n",
      "\n",
      "Training on fold [2/5]\n",
      "\n",
      "bestTest = 0.9622962328\n",
      "bestIteration = 467\n",
      "\n",
      "Training on fold [3/5]\n",
      "\n",
      "bestTest = 0.9711505917\n",
      "bestIteration = 408\n",
      "\n",
      "Training on fold [4/5]\n",
      "\n",
      "bestTest = 0.9650719124\n",
      "bestIteration = 411\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['loss_function'] = 'Logloss'\n",
    "params['iterations'] = 1000\n",
    "params['custom_loss'] = 'F1'\n",
    "params['random_seed'] = 27\n",
    "params['learning_rate'] = 0.1\n",
    "params['eval_metric'] = 'AUC'\n",
    "\n",
    "cbc_cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(features_train_cat, label=target_train_cat, text_features=['clear_text']),\n",
    "    fold_count = 5,\n",
    "    shuffle = True,\n",
    "    partition_random_seed = 0,\n",
    "    plot = True,\n",
    "    stratified = True,\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-AUC-mean</th>\n",
       "      <th>test-AUC-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "      <th>test-F1-mean</th>\n",
       "      <th>test-F1-std</th>\n",
       "      <th>train-F1-mean</th>\n",
       "      <th>train-F1-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.844089</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.562393</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.563788</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.727462</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.693873</td>\n",
       "      <td>0.005372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.851356</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.467832</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.470398</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.720193</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.688457</td>\n",
       "      <td>0.002446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.884754</td>\n",
       "      <td>0.022897</td>\n",
       "      <td>0.390650</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.394315</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.720457</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.689057</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.901833</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.334304</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.338856</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.720205</td>\n",
       "      <td>0.007129</td>\n",
       "      <td>0.689032</td>\n",
       "      <td>0.004111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.911614</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.293845</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.299067</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.683008</td>\n",
       "      <td>0.004370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iterations  test-AUC-mean  test-AUC-std  test-Logloss-mean  \\\n",
       "0           0       0.844089      0.004504           0.562393   \n",
       "1           1       0.851356      0.006995           0.467832   \n",
       "2           2       0.884754      0.022897           0.390650   \n",
       "3           3       0.901833      0.013739           0.334304   \n",
       "4           4       0.911614      0.008179           0.293845   \n",
       "\n",
       "   test-Logloss-std  train-Logloss-mean  train-Logloss-std  test-F1-mean  \\\n",
       "0          0.001547            0.563788           0.001666      0.727462   \n",
       "1          0.002214            0.470398           0.002385      0.720193   \n",
       "2          0.004475            0.394315           0.004110      0.720457   \n",
       "3          0.003795            0.338856           0.003614      0.720205   \n",
       "4          0.002384            0.299067           0.002927      0.713873   \n",
       "\n",
       "   test-F1-std  train-F1-mean  train-F1-std  \n",
       "0     0.003281       0.693873      0.005372  \n",
       "1     0.006393       0.688457      0.002446  \n",
       "2     0.006299       0.689057      0.002129  \n",
       "3     0.007129       0.689032      0.004111  \n",
       "4     0.005336       0.683008      0.004370  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_cv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшее значение AUC = 0.9677801151434086\n",
      "лучшая итерация - 793\n",
      "F1 =  0.7674309537338218\n"
     ]
    }
   ],
   "source": [
    "best_value = np.max(cbc_cv_data['test-AUC-mean'])\n",
    "best_iter = np.argmax(cbc_cv_data['test-AUC-mean'])\n",
    "\n",
    "print('Лучшее значение AUC =', best_value)\n",
    "print('лучшая итерация -', best_iter)\n",
    "print('F1 = ', cbc_cv_data.loc[793, 'test-F1-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iterations            793.000000\n",
       "test-AUC-mean           0.967780\n",
       "test-AUC-std            0.003951\n",
       "test-Logloss-mean       0.115392\n",
       "test-Logloss-std        0.003521\n",
       "train-Logloss-mean      0.101209\n",
       "train-Logloss-std       0.004596\n",
       "test-F1-mean            0.767431\n",
       "test-F1-std             0.007729\n",
       "train-F1-mean           0.801862\n",
       "train-F1-std            0.010711\n",
       "Name: 793, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_cv_data.loc[793]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом на 793 итерации мы получаем наибольшее значение AUC, а следовательно и наибольшее значение F1. \n",
    "\n",
    "F1 =  0.767430"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Мы обучали CatBoost при помощи кросс-валидации и следили чтобы модель не переобучилась. Итоговое значение F1 = 0.767430 на 793 итерации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим CatBoost на train и сделаем итоговые предсказания на тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 1)\n",
      "(119678,)\n",
      "(39893, 1)\n",
      "(39893,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_cat.shape)\n",
    "print(target_train_cat.shape)\n",
    "print(features_test_cat.shape)\n",
    "print(target_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5633283\ttotal: 532ms\tremaining: 7m 1s\n",
      "10:\tlearn: 0.1851787\ttotal: 5.96s\tremaining: 7m 3s\n",
      "20:\tlearn: 0.1529705\ttotal: 11.6s\tremaining: 7m 6s\n",
      "30:\tlearn: 0.1443914\ttotal: 17.1s\tremaining: 7m\n",
      "40:\tlearn: 0.1393873\ttotal: 22.7s\tremaining: 6m 56s\n",
      "50:\tlearn: 0.1359681\ttotal: 28.4s\tremaining: 6m 52s\n",
      "60:\tlearn: 0.1333928\ttotal: 33.8s\tremaining: 6m 45s\n",
      "70:\tlearn: 0.1313524\ttotal: 39.1s\tremaining: 6m 37s\n",
      "80:\tlearn: 0.1294760\ttotal: 44.6s\tremaining: 6m 31s\n",
      "90:\tlearn: 0.1278001\ttotal: 50.1s\tremaining: 6m 26s\n",
      "100:\tlearn: 0.1260297\ttotal: 55.8s\tremaining: 6m 22s\n",
      "110:\tlearn: 0.1248336\ttotal: 1m 1s\tremaining: 6m 15s\n",
      "120:\tlearn: 0.1235276\ttotal: 1m 6s\tremaining: 6m 9s\n",
      "130:\tlearn: 0.1221555\ttotal: 1m 12s\tremaining: 6m 4s\n",
      "140:\tlearn: 0.1207755\ttotal: 1m 17s\tremaining: 5m 59s\n",
      "150:\tlearn: 0.1200894\ttotal: 1m 23s\tremaining: 5m 54s\n",
      "160:\tlearn: 0.1193544\ttotal: 1m 28s\tremaining: 5m 46s\n",
      "170:\tlearn: 0.1185480\ttotal: 1m 33s\tremaining: 5m 41s\n",
      "180:\tlearn: 0.1177741\ttotal: 1m 39s\tremaining: 5m 38s\n",
      "190:\tlearn: 0.1170701\ttotal: 1m 46s\tremaining: 5m 34s\n",
      "200:\tlearn: 0.1162371\ttotal: 1m 52s\tremaining: 5m 30s\n",
      "210:\tlearn: 0.1155801\ttotal: 1m 58s\tremaining: 5m 25s\n",
      "220:\tlearn: 0.1149479\ttotal: 2m 3s\tremaining: 5m 19s\n",
      "230:\tlearn: 0.1143121\ttotal: 2m 8s\tremaining: 5m 13s\n",
      "240:\tlearn: 0.1137280\ttotal: 2m 14s\tremaining: 5m 7s\n",
      "250:\tlearn: 0.1130645\ttotal: 2m 19s\tremaining: 5m 1s\n",
      "260:\tlearn: 0.1124932\ttotal: 2m 24s\tremaining: 4m 55s\n",
      "270:\tlearn: 0.1118820\ttotal: 2m 30s\tremaining: 4m 49s\n",
      "280:\tlearn: 0.1112800\ttotal: 2m 35s\tremaining: 4m 43s\n",
      "290:\tlearn: 0.1108027\ttotal: 2m 40s\tremaining: 4m 36s\n",
      "300:\tlearn: 0.1103797\ttotal: 2m 45s\tremaining: 4m 30s\n",
      "310:\tlearn: 0.1099047\ttotal: 2m 51s\tremaining: 4m 25s\n",
      "320:\tlearn: 0.1093916\ttotal: 2m 56s\tremaining: 4m 20s\n",
      "330:\tlearn: 0.1089086\ttotal: 3m 2s\tremaining: 4m 14s\n",
      "340:\tlearn: 0.1084773\ttotal: 3m 7s\tremaining: 4m 8s\n",
      "350:\tlearn: 0.1079985\ttotal: 3m 12s\tremaining: 4m 2s\n",
      "360:\tlearn: 0.1075092\ttotal: 3m 17s\tremaining: 3m 56s\n",
      "370:\tlearn: 0.1070147\ttotal: 3m 23s\tremaining: 3m 51s\n",
      "380:\tlearn: 0.1066214\ttotal: 3m 28s\tremaining: 3m 45s\n",
      "390:\tlearn: 0.1061704\ttotal: 3m 33s\tremaining: 3m 39s\n",
      "400:\tlearn: 0.1056817\ttotal: 3m 39s\tremaining: 3m 34s\n",
      "410:\tlearn: 0.1052648\ttotal: 3m 44s\tremaining: 3m 28s\n",
      "420:\tlearn: 0.1048910\ttotal: 3m 50s\tremaining: 3m 23s\n",
      "430:\tlearn: 0.1045504\ttotal: 3m 55s\tremaining: 3m 17s\n",
      "440:\tlearn: 0.1042330\ttotal: 4m\tremaining: 3m 12s\n",
      "450:\tlearn: 0.1038463\ttotal: 4m 6s\tremaining: 3m 6s\n",
      "460:\tlearn: 0.1035114\ttotal: 4m 11s\tremaining: 3m 1s\n",
      "470:\tlearn: 0.1031019\ttotal: 4m 17s\tremaining: 2m 56s\n",
      "480:\tlearn: 0.1028043\ttotal: 4m 23s\tremaining: 2m 50s\n",
      "490:\tlearn: 0.1024764\ttotal: 4m 28s\tremaining: 2m 45s\n",
      "500:\tlearn: 0.1021053\ttotal: 4m 33s\tremaining: 2m 39s\n",
      "510:\tlearn: 0.1017349\ttotal: 4m 39s\tremaining: 2m 34s\n",
      "520:\tlearn: 0.1014219\ttotal: 4m 44s\tremaining: 2m 28s\n",
      "530:\tlearn: 0.1010857\ttotal: 4m 49s\tremaining: 2m 22s\n",
      "540:\tlearn: 0.1007755\ttotal: 4m 55s\tremaining: 2m 17s\n",
      "550:\tlearn: 0.1004354\ttotal: 5m 1s\tremaining: 2m 12s\n",
      "560:\tlearn: 0.1000979\ttotal: 5m 8s\tremaining: 2m 7s\n",
      "570:\tlearn: 0.0997629\ttotal: 5m 14s\tremaining: 2m 2s\n",
      "580:\tlearn: 0.0994670\ttotal: 5m 20s\tremaining: 1m 57s\n",
      "590:\tlearn: 0.0991730\ttotal: 5m 26s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.0989083\ttotal: 5m 31s\tremaining: 1m 45s\n",
      "610:\tlearn: 0.0985877\ttotal: 5m 37s\tremaining: 1m 40s\n",
      "620:\tlearn: 0.0983030\ttotal: 5m 43s\tremaining: 1m 35s\n",
      "630:\tlearn: 0.0980366\ttotal: 5m 49s\tremaining: 1m 29s\n",
      "640:\tlearn: 0.0977461\ttotal: 5m 55s\tremaining: 1m 24s\n",
      "650:\tlearn: 0.0973841\ttotal: 6m 1s\tremaining: 1m 18s\n",
      "660:\tlearn: 0.0970778\ttotal: 6m 7s\tremaining: 1m 13s\n",
      "670:\tlearn: 0.0967923\ttotal: 6m 12s\tremaining: 1m 7s\n",
      "680:\tlearn: 0.0964884\ttotal: 6m 18s\tremaining: 1m 2s\n",
      "690:\tlearn: 0.0962441\ttotal: 6m 24s\tremaining: 56.8s\n",
      "700:\tlearn: 0.0960311\ttotal: 6m 30s\tremaining: 51.3s\n",
      "710:\tlearn: 0.0957247\ttotal: 6m 36s\tremaining: 45.7s\n",
      "720:\tlearn: 0.0954879\ttotal: 6m 41s\tremaining: 40.1s\n",
      "730:\tlearn: 0.0952304\ttotal: 6m 47s\tremaining: 34.5s\n",
      "740:\tlearn: 0.0949585\ttotal: 6m 52s\tremaining: 29s\n",
      "750:\tlearn: 0.0947085\ttotal: 6m 58s\tremaining: 23.4s\n",
      "760:\tlearn: 0.0944370\ttotal: 7m 3s\tremaining: 17.8s\n",
      "770:\tlearn: 0.0942080\ttotal: 7m 9s\tremaining: 12.3s\n",
      "780:\tlearn: 0.0939571\ttotal: 7m 16s\tremaining: 6.7s\n",
      "790:\tlearn: 0.0936772\ttotal: 7m 22s\tremaining: 1.12s\n",
      "792:\tlearn: 0.0936453\ttotal: 7m 23s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fbad9b6a820>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=793,\n",
    "    random_seed=27,\n",
    "    learning_rate=0.1,\n",
    "    text_features=['clear_text'],\n",
    "    custom_loss = ['AUC', 'F1']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    features_train_cat, target_train_cat,\n",
    "    verbose=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_test = 0.7763351626288314\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(features_test_cat)\n",
    "f1_test = f1_score(target_test_cat, predictions)\n",
    "\n",
    "print(f'F1_test = {f1_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте нам необходимо было определять тональность текста. Данные были на английском языке, классы несбалансированные.\n",
    "\n",
    "Мы использовали как простые модели машинного обучения (логистическая регрессия, дерево решений, случайный лес), так и градиентный бустинг.\n",
    "\n",
    "При обучении простых моделей использовали GridSearchCV и Pipeline для подбора лучших гиперпараметров и правильного разделения на выборки.\n",
    "\n",
    "Лучше всех с этой задачей справился CatBoost. Его мы обучали двумя способами: через GridSearchCV и через построение графиков AUC и F1 во время кросс-валидации в реальном времени. Обучая вторым способом мы определили, что после 793 итерации модель начинает переобучаться. На кросс-валидации модель показала F1 = 0.767430.\n",
    "\n",
    "Обучив модель мы сделали предсказания на отложенной тестовой выборке. F1_test = 0.776335."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1394,
    "start_time": "2022-05-07T08:01:59.682Z"
   },
   {
    "duration": 154,
    "start_time": "2022-05-07T08:02:50.323Z"
   },
   {
    "duration": 1151,
    "start_time": "2022-05-07T08:03:14.525Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-07T08:11:17.824Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T08:12:14.316Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T08:13:02.730Z"
   },
   {
    "duration": 64,
    "start_time": "2022-05-07T08:13:55.892Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-07T08:14:11.161Z"
   },
   {
    "duration": 900,
    "start_time": "2022-05-07T08:15:20.773Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-07T08:25:05.624Z"
   },
   {
    "duration": 192,
    "start_time": "2022-05-07T08:27:35.025Z"
   },
   {
    "duration": 95287,
    "start_time": "2022-05-07T08:28:00.901Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-07T08:29:36.190Z"
   },
   {
    "duration": 1382,
    "start_time": "2022-05-07T08:29:50.143Z"
   },
   {
    "duration": 854,
    "start_time": "2022-05-07T08:29:52.469Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-07T08:29:55.211Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T08:29:59.531Z"
   },
   {
    "duration": 637,
    "start_time": "2022-05-07T08:30:03.469Z"
   },
   {
    "duration": 3867,
    "start_time": "2022-05-07T08:30:30.253Z"
   },
   {
    "duration": 1386,
    "start_time": "2022-05-07T09:10:20.161Z"
   },
   {
    "duration": 796,
    "start_time": "2022-05-07T09:10:23.317Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-07T09:10:33.743Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:16:43.216Z"
   },
   {
    "duration": 817,
    "start_time": "2022-05-07T09:16:45.453Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-07T09:16:48.905Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:29:15.716Z"
   },
   {
    "duration": 723,
    "start_time": "2022-05-07T09:29:20.450Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-07T09:29:21.835Z"
   },
   {
    "duration": 168,
    "start_time": "2022-05-07T09:29:52.210Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:31:26.032Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:31:29.605Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:33:25.529Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-07T09:35:10.419Z"
   },
   {
    "duration": 1882,
    "start_time": "2022-05-07T09:35:11.474Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:38:22.504Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-07T09:38:45.119Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:38:59.560Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-07T09:39:09.208Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:40:49.121Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:40:49.657Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-07T09:40:50.360Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:41:14.810Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:41:15.873Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:41:16.276Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:41:20.167Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:42:08.432Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:42:09.914Z"
   },
   {
    "duration": 3858,
    "start_time": "2022-05-07T09:42:27.242Z"
   },
   {
    "duration": 71643,
    "start_time": "2022-05-07T09:42:37.715Z"
   },
   {
    "duration": 3171,
    "start_time": "2022-05-07T09:44:42.331Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-07T09:44:53.633Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:47:56.894Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:47:57.915Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:48:36.776Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:48:37.184Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:48:41.674Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:48:43.290Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:49:13.729Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:49:14.126Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:50:06.514Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:50:23.064Z"
   },
   {
    "duration": 711,
    "start_time": "2022-05-07T09:50:23.494Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-07T09:50:24.977Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:50:26.911Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:50:29.164Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:50:31.110Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:50:57.398Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:52:03.232Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:52:04.108Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:52:15.809Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:52:16.267Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T09:52:32.537Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:52:33.157Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T09:55:38.117Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:55:38.734Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-07T09:58:30.127Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T09:58:35.097Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:00:47.944Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:00:50.800Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:01:01.144Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T10:01:01.555Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:01:16.741Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:01:17.567Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:01:37.776Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:01:38.104Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:02:11.135Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:09:13.802Z"
   },
   {
    "duration": 188,
    "start_time": "2022-05-07T10:09:34.265Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:09:44.604Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:11:22.311Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:12:21.151Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:12:35.174Z"
   },
   {
    "duration": 1872,
    "start_time": "2022-05-07T10:13:38.659Z"
   },
   {
    "duration": 71188,
    "start_time": "2022-05-07T10:13:57.277Z"
   },
   {
    "duration": 10219,
    "start_time": "2022-05-07T10:15:13.957Z"
   },
   {
    "duration": 70791,
    "start_time": "2022-05-07T10:15:58.915Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T10:17:44.448Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:18:58.513Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-07T10:22:00.382Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-07T10:22:55.299Z"
   },
   {
    "duration": 1356,
    "start_time": "2022-05-07T10:23:15.647Z"
   },
   {
    "duration": 823,
    "start_time": "2022-05-07T10:23:17.005Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-07T10:23:18.602Z"
   },
   {
    "duration": 211,
    "start_time": "2022-05-07T10:23:19.751Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T10:23:21.204Z"
   },
   {
    "duration": 1111,
    "start_time": "2022-05-07T10:23:23.010Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:23:35.804Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T10:23:53.070Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:24:08.793Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:24:33.035Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-07T10:24:41.027Z"
   },
   {
    "duration": 1872,
    "start_time": "2022-05-07T10:25:03.441Z"
   },
   {
    "duration": 70227,
    "start_time": "2022-05-07T10:25:16.320Z"
   },
   {
    "duration": 9932,
    "start_time": "2022-05-07T10:27:17.297Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T10:27:31.016Z"
   },
   {
    "duration": 122,
    "start_time": "2022-05-07T10:28:32.363Z"
   },
   {
    "duration": 81,
    "start_time": "2022-05-07T10:28:33.822Z"
   },
   {
    "duration": 55696,
    "start_time": "2022-05-07T10:31:53.526Z"
   },
   {
    "duration": 1752,
    "start_time": "2022-05-07T10:38:48.586Z"
   },
   {
    "duration": 1710,
    "start_time": "2022-05-07T10:39:31.301Z"
   },
   {
    "duration": 1721,
    "start_time": "2022-05-07T10:40:11.106Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T10:41:03.529Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-07T10:42:19.802Z"
   },
   {
    "duration": 198,
    "start_time": "2022-05-07T10:42:24.277Z"
   },
   {
    "duration": 1724,
    "start_time": "2022-05-07T10:42:29.164Z"
   },
   {
    "duration": 1744,
    "start_time": "2022-05-07T10:43:14.111Z"
   },
   {
    "duration": 1701,
    "start_time": "2022-05-07T10:43:47.223Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-07T10:45:10.404Z"
   },
   {
    "duration": 1014197,
    "start_time": "2022-05-07T10:45:53.808Z"
   },
   {
    "duration": 60318,
    "start_time": "2022-05-07T11:02:50.595Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-07T11:04:39.051Z"
   },
   {
    "duration": 3107,
    "start_time": "2022-05-07T11:04:46.283Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-07T11:05:03.102Z"
   },
   {
    "duration": 126659,
    "start_time": "2022-05-07T11:05:40.885Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-07T11:08:03.606Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-07T11:08:09.146Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T11:08:22.568Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-07T11:08:30.123Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T11:08:33.941Z"
   },
   {
    "duration": 9138,
    "start_time": "2022-05-07T11:11:08.350Z"
   },
   {
    "duration": 6786,
    "start_time": "2022-05-07T11:11:22.914Z"
   },
   {
    "duration": 10315,
    "start_time": "2022-05-07T11:11:38.099Z"
   },
   {
    "duration": 9243,
    "start_time": "2022-05-07T11:12:01.652Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-07T11:14:16.171Z"
   },
   {
    "duration": 66057,
    "start_time": "2022-05-07T11:14:38.045Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-07T11:15:44.105Z"
   },
   {
    "duration": 14791,
    "start_time": "2022-05-07T11:15:44.120Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-07T11:15:58.914Z"
   },
   {
    "duration": 22598,
    "start_time": "2022-05-07T11:20:00.552Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T11:20:29.777Z"
   },
   {
    "duration": 73153,
    "start_time": "2022-05-07T11:20:45.824Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T11:21:58.979Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-07T11:22:08.838Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-07T11:22:53.517Z"
   },
   {
    "duration": 726,
    "start_time": "2022-05-07T11:23:12.303Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-07T11:25:58.024Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-07T11:26:23.839Z"
   },
   {
    "duration": 200,
    "start_time": "2022-05-07T11:34:18.658Z"
   },
   {
    "duration": 192,
    "start_time": "2022-05-07T11:34:35.333Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-07T11:35:20.479Z"
   },
   {
    "duration": 2518969,
    "start_time": "2022-05-07T11:35:35.774Z"
   },
   {
    "duration": 30245,
    "start_time": "2022-05-07T12:18:08.734Z"
   },
   {
    "duration": 78963,
    "start_time": "2022-05-07T12:18:49.271Z"
   },
   {
    "duration": 42438,
    "start_time": "2022-05-07T12:20:50.000Z"
   },
   {
    "duration": 331,
    "start_time": "2022-05-07T12:21:56.749Z"
   },
   {
    "duration": 641688,
    "start_time": "2022-05-07T12:26:06.877Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-07T12:36:51.761Z"
   },
   {
    "duration": 66739,
    "start_time": "2022-05-07T12:38:17.343Z"
   },
   {
    "duration": 325,
    "start_time": "2022-05-07T12:39:26.598Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-07T12:39:31.793Z"
   },
   {
    "duration": 53630,
    "start_time": "2022-05-07T12:42:17.887Z"
   },
   {
    "duration": 3444,
    "start_time": "2022-05-10T12:01:59.718Z"
   },
   {
    "duration": 22127,
    "start_time": "2022-05-10T12:02:05.728Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-10T12:02:33.070Z"
   },
   {
    "duration": 247,
    "start_time": "2022-05-10T12:06:03.317Z"
   },
   {
    "duration": 1628,
    "start_time": "2022-05-10T12:06:07.277Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-10T12:06:13.096Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-10T12:06:18.098Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-10T12:08:39.538Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-10T12:08:40.637Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-10T12:08:42.937Z"
   },
   {
    "duration": 5225,
    "start_time": "2022-05-10T12:08:55.398Z"
   },
   {
    "duration": 88111,
    "start_time": "2022-05-10T12:09:26.337Z"
   },
   {
    "duration": 12354,
    "start_time": "2022-05-10T12:11:04.626Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-10T12:12:05.078Z"
   },
   {
    "duration": 129,
    "start_time": "2022-05-10T12:12:05.958Z"
   },
   {
    "duration": 64,
    "start_time": "2022-05-10T12:13:07.279Z"
   },
   {
    "duration": 157,
    "start_time": "2022-05-10T12:20:50.679Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-10T12:21:07.831Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-10T12:21:14.479Z"
   },
   {
    "duration": 30328,
    "start_time": "2022-05-10T12:21:29.124Z"
   },
   {
    "duration": 221876,
    "start_time": "2022-05-10T12:22:15.759Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-10T12:26:25.819Z"
   },
   {
    "duration": 216668,
    "start_time": "2022-05-10T12:33:55.117Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T12:37:31.787Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-10T12:37:31.793Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-10T12:37:31.808Z"
   },
   {
    "duration": 67960,
    "start_time": "2022-05-10T12:42:06.357Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-10T12:43:14.319Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-10T12:43:14.326Z"
   },
   {
    "duration": 29,
    "start_time": "2022-05-10T12:43:14.360Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-10T12:54:17.517Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T12:54:30.557Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-10T12:55:12.317Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-10T12:55:23.397Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-10T12:59:06.597Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-10T12:59:23.311Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-10T13:06:02.337Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T13:06:35.957Z"
   },
   {
    "duration": 194,
    "start_time": "2022-05-10T13:25:43.719Z"
   },
   {
    "duration": 412,
    "start_time": "2022-05-10T13:25:51.759Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-10T13:27:30.998Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-10T13:27:44.719Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-10T13:28:19.318Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-10T13:28:34.278Z"
   },
   {
    "duration": 57348,
    "start_time": "2022-05-10T13:28:46.318Z"
   },
   {
    "duration": 1869,
    "start_time": "2022-05-10T13:30:22.478Z"
   },
   {
    "duration": 140383,
    "start_time": "2022-05-10T13:31:00.418Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-10T13:33:20.803Z"
   },
   {
    "duration": 1655,
    "start_time": "2022-05-10T13:33:42.485Z"
   },
   {
    "duration": 881,
    "start_time": "2022-05-10T13:33:45.805Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-10T13:33:48.884Z"
   },
   {
    "duration": 154,
    "start_time": "2022-05-10T13:33:50.625Z"
   },
   {
    "duration": 1244,
    "start_time": "2022-05-10T13:33:51.777Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T13:33:53.846Z"
   },
   {
    "duration": 3292,
    "start_time": "2022-05-10T13:33:55.606Z"
   },
   {
    "duration": 83663,
    "start_time": "2022-05-10T13:33:58.900Z"
   },
   {
    "duration": 11768,
    "start_time": "2022-05-10T13:35:22.564Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-10T13:35:34.335Z"
   },
   {
    "duration": 117,
    "start_time": "2022-05-10T13:35:34.340Z"
   },
   {
    "duration": 52,
    "start_time": "2022-05-10T13:35:34.459Z"
   },
   {
    "duration": 216718,
    "start_time": "2022-05-10T13:35:56.725Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-10T13:39:33.445Z"
   },
   {
    "duration": 276125,
    "start_time": "2022-05-10T13:39:38.345Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-10T13:44:14.472Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-10T13:44:14.479Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-10T13:44:14.494Z"
   },
   {
    "duration": 63609,
    "start_time": "2022-05-10T13:44:14.514Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T13:45:18.126Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T13:45:18.133Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-10T13:45:18.139Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-10T13:45:18.152Z"
   },
   {
    "duration": 66,
    "start_time": "2022-05-10T13:45:18.165Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-10T13:45:18.233Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T13:45:18.262Z"
   },
   {
    "duration": 6278417,
    "start_time": "2022-05-10T13:45:18.268Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-10T15:29:56.687Z"
   },
   {
    "duration": 43,
    "start_time": "2022-05-10T15:29:56.692Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-10T15:29:56.737Z"
   },
   {
    "duration": 1417,
    "start_time": "2022-05-11T15:26:14.185Z"
   },
   {
    "duration": 875,
    "start_time": "2022-05-11T15:26:16.233Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-11T15:26:17.456Z"
   },
   {
    "duration": 196,
    "start_time": "2022-05-11T15:26:19.007Z"
   },
   {
    "duration": 1224,
    "start_time": "2022-05-11T15:26:20.072Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-11T15:26:21.311Z"
   },
   {
    "duration": 3147,
    "start_time": "2022-05-11T15:26:22.495Z"
   },
   {
    "duration": 78970,
    "start_time": "2022-05-11T15:26:25.644Z"
   },
   {
    "duration": 11416,
    "start_time": "2022-05-11T15:27:44.615Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-11T15:27:56.033Z"
   },
   {
    "duration": 128,
    "start_time": "2022-05-11T15:27:56.037Z"
   },
   {
    "duration": 53,
    "start_time": "2022-05-11T15:27:56.167Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-11T15:28:13.741Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-11T15:28:14.556Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-11T15:28:16.452Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-11T15:28:17.277Z"
   },
   {
    "duration": 139,
    "start_time": "2022-05-11T16:29:31.305Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-11T16:29:40.423Z"
   },
   {
    "duration": 1829,
    "start_time": "2022-05-12T09:53:50.471Z"
   },
   {
    "duration": 934,
    "start_time": "2022-05-12T09:53:52.302Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-12T09:53:54.027Z"
   },
   {
    "duration": 408,
    "start_time": "2022-05-12T09:53:54.989Z"
   },
   {
    "duration": 1380,
    "start_time": "2022-05-12T09:53:56.439Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-12T09:53:57.821Z"
   },
   {
    "duration": 3166,
    "start_time": "2022-05-12T09:53:58.634Z"
   },
   {
    "duration": 80179,
    "start_time": "2022-05-12T09:54:01.803Z"
   },
   {
    "duration": 11810,
    "start_time": "2022-05-12T09:55:21.984Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T09:55:33.796Z"
   },
   {
    "duration": 132,
    "start_time": "2022-05-12T09:55:33.801Z"
   },
   {
    "duration": 52,
    "start_time": "2022-05-12T09:55:33.935Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-12T09:55:33.989Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-12T10:02:02.500Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-12T10:02:07.785Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-12T10:02:08.913Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-12T10:02:09.672Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T10:02:23.750Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-12T10:02:42.190Z"
   },
   {
    "duration": 123,
    "start_time": "2022-05-12T10:06:59.468Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-12T10:07:10.859Z"
   },
   {
    "duration": 7584,
    "start_time": "2022-05-12T10:07:15.880Z"
   },
   {
    "duration": 6673,
    "start_time": "2022-05-12T10:08:02.828Z"
   },
   {
    "duration": 6941,
    "start_time": "2022-05-12T10:11:29.307Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-12T10:16:44.079Z"
   },
   {
    "duration": 56606,
    "start_time": "2022-05-12T10:16:51.479Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-12T10:18:53.473Z"
   },
   {
    "duration": 56316,
    "start_time": "2022-05-12T10:20:31.867Z"
   },
   {
    "duration": 58032,
    "start_time": "2022-05-12T10:25:51.270Z"
   },
   {
    "duration": 260697,
    "start_time": "2022-05-12T10:28:20.227Z"
   },
   {
    "duration": 657543,
    "start_time": "2022-05-12T10:37:42.945Z"
   },
   {
    "duration": 95,
    "start_time": "2022-05-12T10:51:00.586Z"
   },
   {
    "duration": 73,
    "start_time": "2022-05-12T10:51:38.149Z"
   },
   {
    "duration": 99231,
    "start_time": "2022-05-12T10:51:52.601Z"
   },
   {
    "duration": 1368581,
    "start_time": "2022-05-12T10:53:38.300Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-12T11:27:05.980Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-12T11:27:15.945Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-12T11:30:39.637Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-12T11:30:54.709Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-12T11:30:59.026Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-12T11:32:03.035Z"
   },
   {
    "duration": 3107,
    "start_time": "2022-05-12T11:32:16.668Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-12T11:32:23.940Z"
   },
   {
    "duration": 1409429,
    "start_time": "2022-05-12T11:44:43.788Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-12T12:08:13.219Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-12T12:08:13.239Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-12T12:28:29.390Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-12T12:28:36.666Z"
   },
   {
    "duration": 1792,
    "start_time": "2022-05-12T15:30:07.383Z"
   },
   {
    "duration": 908,
    "start_time": "2022-05-12T15:30:09.894Z"
   },
   {
    "duration": 49,
    "start_time": "2022-05-12T15:30:11.447Z"
   },
   {
    "duration": 395,
    "start_time": "2022-05-12T15:30:13.201Z"
   },
   {
    "duration": 1382,
    "start_time": "2022-05-12T15:30:13.870Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-12T15:30:15.255Z"
   },
   {
    "duration": 3391,
    "start_time": "2022-05-12T15:30:15.267Z"
   },
   {
    "duration": 97558,
    "start_time": "2022-05-12T15:30:18.660Z"
   },
   {
    "duration": 29450,
    "start_time": "2022-05-12T15:31:56.220Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-12T15:32:25.671Z"
   },
   {
    "duration": 105,
    "start_time": "2022-05-12T15:32:25.676Z"
   },
   {
    "duration": 70,
    "start_time": "2022-05-12T15:32:25.783Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-12T15:32:25.855Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-12T15:52:49.201Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-12T15:52:50.261Z"
   },
   {
    "duration": 33,
    "start_time": "2022-05-12T15:52:52.321Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-12T15:52:53.185Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-12T15:53:01.089Z"
   },
   {
    "duration": 122561,
    "start_time": "2022-05-12T15:58:53.707Z"
   },
   {
    "duration": 27164,
    "start_time": "2022-05-12T16:01:25.218Z"
   },
   {
    "duration": 36189,
    "start_time": "2022-05-12T16:02:34.293Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-12T16:03:32.309Z"
   },
   {
    "duration": 44806,
    "start_time": "2022-05-12T16:03:43.990Z"
   },
   {
    "duration": 455154,
    "start_time": "2022-05-12T16:04:30.332Z"
   },
   {
    "duration": 5574,
    "start_time": "2022-05-12T16:12:05.488Z"
   },
   {
    "duration": 2157,
    "start_time": "2022-05-13T16:05:50.925Z"
   },
   {
    "duration": 1057,
    "start_time": "2022-05-13T16:06:04.140Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-13T16:06:06.147Z"
   },
   {
    "duration": 215,
    "start_time": "2022-05-13T16:06:08.676Z"
   },
   {
    "duration": 2038,
    "start_time": "2022-05-13T16:06:12.420Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-13T16:06:17.075Z"
   },
   {
    "duration": 4352,
    "start_time": "2022-05-13T16:06:18.907Z"
   },
   {
    "duration": 132644,
    "start_time": "2022-05-13T16:06:23.262Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-13T16:10:30.628Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-13T16:10:44.357Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-13T16:28:26.010Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:29:23.126Z"
   },
   {
    "duration": 193,
    "start_time": "2022-05-13T16:29:34.454Z"
   },
   {
    "duration": 125,
    "start_time": "2022-05-13T16:29:49.851Z"
   },
   {
    "duration": 170,
    "start_time": "2022-05-13T16:32:16.275Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-13T16:32:21.707Z"
   },
   {
    "duration": 40,
    "start_time": "2022-05-13T16:32:22.242Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-13T16:32:23.555Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T16:32:24.018Z"
   },
   {
    "duration": 122,
    "start_time": "2022-05-13T16:32:24.396Z"
   },
   {
    "duration": 122,
    "start_time": "2022-05-13T16:36:19.261Z"
   },
   {
    "duration": 110,
    "start_time": "2022-05-13T16:36:42.460Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-13T17:39:26.929Z"
   },
   {
    "duration": 986,
    "start_time": "2022-05-13T17:39:28.479Z"
   },
   {
    "duration": 44,
    "start_time": "2022-05-13T17:39:29.467Z"
   },
   {
    "duration": 215,
    "start_time": "2022-05-13T17:39:30.762Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-13T17:39:32.215Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-13T17:39:33.053Z"
   },
   {
    "duration": 4458,
    "start_time": "2022-05-13T17:39:33.885Z"
   },
   {
    "duration": 130789,
    "start_time": "2022-05-13T17:39:38.346Z"
   },
   {
    "duration": 50,
    "start_time": "2022-05-13T17:41:56.154Z"
   },
   {
    "duration": 39,
    "start_time": "2022-05-13T17:41:56.875Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-13T17:41:59.213Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T17:42:01.676Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-13T17:42:04.846Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-13T17:42:14.402Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-13T17:44:15.643Z"
   },
   {
    "duration": 63,
    "start_time": "2022-05-13T17:44:29.641Z"
   },
   {
    "duration": 239193,
    "start_time": "2022-05-13T17:46:11.119Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-13T17:54:15.522Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-13T17:56:58.042Z"
   },
   {
    "duration": 57,
    "start_time": "2022-05-13T17:57:21.333Z"
   },
   {
    "duration": 96,
    "start_time": "2022-05-13T18:38:49.234Z"
   },
   {
    "duration": 2484,
    "start_time": "2022-05-13T19:13:20.876Z"
   },
   {
    "duration": 1576,
    "start_time": "2022-05-13T19:13:23.363Z"
   },
   {
    "duration": 62,
    "start_time": "2022-05-13T19:13:24.942Z"
   },
   {
    "duration": 151,
    "start_time": "2022-05-13T19:13:27.845Z"
   },
   {
    "duration": 2038,
    "start_time": "2022-05-13T19:13:31.399Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-13T19:13:33.441Z"
   },
   {
    "duration": 4841,
    "start_time": "2022-05-13T19:13:33.450Z"
   },
   {
    "duration": 135978,
    "start_time": "2022-05-13T19:13:41.552Z"
   },
   {
    "duration": 54,
    "start_time": "2022-05-13T19:16:03.120Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-13T19:16:04.644Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-13T19:16:10.834Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-13T19:16:18.035Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T19:16:19.221Z"
   },
   {
    "duration": 242859,
    "start_time": "2022-05-13T19:16:36.262Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-13T19:20:39.124Z"
   },
   {
    "duration": 261,
    "start_time": "2022-05-13T19:20:39.140Z"
   },
   {
    "duration": 7676,
    "start_time": "2022-05-13T19:21:43.229Z"
   },
   {
    "duration": 164004,
    "start_time": "2022-05-13T19:22:15.598Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-13T19:24:59.605Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-13T19:24:59.613Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-13T19:24:59.625Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-13T19:26:44.395Z"
   },
   {
    "duration": 277193,
    "start_time": "2022-05-13T19:26:56.153Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-13T19:31:33.350Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-13T19:31:33.383Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-13T19:31:33.390Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-13T19:31:33.414Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-13T19:31:33.432Z"
   },
   {
    "duration": 61,
    "start_time": "2022-05-13T19:31:33.448Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-13T19:31:33.512Z"
   },
   {
    "duration": 5695625,
    "start_time": "2022-05-13T19:31:33.519Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-13T21:06:29.148Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-13T21:06:29.156Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
